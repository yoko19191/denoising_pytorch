{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DnCNN Experiments\n",
    "\n",
    "This is a implementation of CT post-reconstruction denosing using DnCNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import built-in liberies\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "# import bsic liberies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# import torch liberies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# import metrics liberies\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr_metric, structural_similarity as ssim_metric\n",
    "\n",
    "# import custom liberies\n",
    "sys.path.insert(0, \"..\")\n",
    "from utils import process, visualize\n",
    "# from models.DnCNN import DnCNN\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define DnCNN Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DnCNN(nn.Module):\n",
    "    def __init__(self, channels=1, num_layers=17, features=64):\n",
    "        super(DnCNN, self).__init__()\n",
    "        layers = [\n",
    "            nn.Conv2d(channels, features, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ]\n",
    "\n",
    "        for _ in range(num_layers - 2):\n",
    "            layers.append(nn.Conv2d(features, features, kernel_size=3, padding=1))\n",
    "            layers.append(nn.BatchNorm2d(features))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "\n",
    "        layers.append(nn.Conv2d(features, channels, kernel_size=3, padding=1))\n",
    "\n",
    "        self.dncnn = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.dncnn(x)\n",
    "        return x - out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parepare CT Sinogram Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the custom dataset\n",
    "class CTSinogramDataset(Dataset):\n",
    "    def __init__(self, clean_folder, noisy_folder, transform=None):\n",
    "        self.clean_folder = clean_folder\n",
    "        self.noisy_folder = noisy_folder\n",
    "        self.transform = transform\n",
    "        self.patient_ids = sorted(os.listdir(clean_folder))\n",
    "\n",
    "        self.clean_slices = {}\n",
    "        self.noisy_slices = {}\n",
    "        for patient_id in self.patient_ids:\n",
    "            clean_patient_folder = os.path.join(clean_folder, patient_id)\n",
    "            noisy_patient_folder = os.path.join(noisy_folder, patient_id)\n",
    "            \n",
    "            clean_slice_files = sorted([f for f in os.listdir(clean_patient_folder) if self.valid_image_ext(f)])\n",
    "            noisy_slice_files = sorted([f for f in os.listdir(noisy_patient_folder) if self.valid_image_ext(f)])\n",
    "\n",
    "            clean_slice_paths = [os.path.join(clean_patient_folder, f) for f in clean_slice_files]\n",
    "            noisy_slice_paths = [os.path.join(noisy_patient_folder, f) for f in noisy_slice_files]\n",
    "\n",
    "            self.clean_slices[patient_id] = clean_slice_paths\n",
    "            self.noisy_slices[patient_id] = noisy_slice_paths\n",
    "        \n",
    "        assert len(self.clean_slices) == len(self.noisy_slices), \\\n",
    "            \"Number of clean slices and noisy slices are not equal.\"\n",
    "        \n",
    "    def valid_image_ext(self, filename):\n",
    "        valid_exts = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif']\n",
    "        ext = os.path.splitext(filename)[-1].lower()\n",
    "        return ext in valid_exts\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.patient_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        patient_id = self.patient_ids[index]\n",
    "\n",
    "        clean_slice_paths = self.clean_slices[patient_id]\n",
    "        noisy_slice_paths = self.noisy_slices[patient_id]\n",
    "\n",
    "        clean_slices = []\n",
    "        for path in clean_slice_paths:\n",
    "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                print(f\"Warning: Skipping a corrupted or missing image at path {path}.\")\n",
    "                continue\n",
    "            clean_slices.append(img)\n",
    "\n",
    "        noisy_slices = []\n",
    "        for path in noisy_slice_paths:\n",
    "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                print(f\"Warning: Skipping a corrupted or missing image at path {path}.\")\n",
    "                continue\n",
    "            noisy_slices.append(img)\n",
    "\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            clean_slices = [self.transform(clean_slice) for clean_slice in clean_slices]\n",
    "            noisy_slices = [self.transform(noisy_slice) for noisy_slice in noisy_slices]\n",
    "        else:\n",
    "            clean_slices = [torch.from_numpy(clean_slice / 255.0).unsqueeze(0) for clean_slice in clean_slices]\n",
    "            noisy_slices = [torch.from_numpy(noisy_slice / 255.0).unsqueeze(0) for noisy_slice in noisy_slices]\n",
    "\n",
    "        return torch.stack(clean_slices), torch.stack(noisy_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:6, val:2, test:2\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "clean_folder = \"../dataset/Kaggle_CT Low Dose Reconstruction/prepared_recon/lam_0\"\n",
    "noisy_folder = \"../dataset/Kaggle_CT Low Dose Reconstruction/prepared_recon/lam_5\"\n",
    "\n",
    "# define data transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# create dataset\n",
    "dataset = CTSinogramDataset(clean_folder, noisy_folder, transform=transform)\n",
    "\n",
    "# calculate dataset length\n",
    "train_len = int(0.6 * len(dataset))\n",
    "val_len = int(0.2 * len(dataset))\n",
    "test_len = len(dataset) - train_len - val_len\n",
    "\n",
    "# random_split dataset\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_len, val_len, test_len])\n",
    "print(f\"train:{len(train_dataset)}, val:{len(val_dataset)}, test:{len(test_dataset)}\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=8, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=8, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 330, 1, 256, 256]) torch.Size([1, 330, 1, 256, 256])\n",
      "range: -1.0 , 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e326e7fc7a54640bb6257b47c57fa33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='slice_idx', max=329), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "clean_batch, noisy_batch = dataiter.next()\n",
    "\n",
    "print(clean_batch.shape, noisy_batch.shape)\n",
    "print(f\"range: {clean_batch[0].min()} , {clean_batch[0].max()}\")\n",
    "\n",
    "# visualize training CT silice\n",
    "visualize.plot_slices(noisy_batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([330, 1, 256, 256])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_batch[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "def calculate_psnr(clean_img, denoised_img):\n",
    "    clean_img = clean_img.squeeze()\n",
    "    denoised_img = denoised_img.squeeze()\n",
    "    #print(\"PSNR\", clean_img.shape, denoised_img.shape)\n",
    "    mse = torch.mean((clean_img - denoised_img) ** 2).item()\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    max_pixel = 1.0\n",
    "    psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
    "    return psnr\n",
    "\n",
    "def calculate_ssim(clean_img, denoised_img):\n",
    "    clean_img_np = clean_img.squeeze().cpu().numpy()\n",
    "    denoised_img_np = denoised_img.squeeze().cpu().numpy()\n",
    "    #print(\"SSIM\", clean_img_np.shape, denoised_img_np.shape)\n",
    "    ssim = ssim_metric(clean_img_np, denoised_img_np, data_range=1.0, win_size=7)\n",
    "    return ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer, scheduler, device, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, (clean_slices, noisy_slices) in enumerate(dataloader):\n",
    "        clean_slices, noisy_slices = clean_slices.to(device), noisy_slices.to(device)\n",
    "\n",
    "        for i in range(clean_slices.size(1)):  # Iterate through each slice\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            clean_slice = clean_slices[:, i, :, :]\n",
    "            noisy_slice = noisy_slices[:, i, :, :]\n",
    "            \n",
    "            outputs = model(noisy_slice)\n",
    "            slice_loss = criterion(outputs, clean_slice)\n",
    "\n",
    "            slice_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += slice_loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    avg_loss = running_loss / (len(dataloader) * clean_slices.size(1))\n",
    "    print(f\"Epoch {epoch + 1}, training Loss: {avg_loss:.4f}\")\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion, device, epoch):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_psnr = 0.0\n",
    "    running_ssim = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (clean_slices, noisy_slices) in enumerate(dataloader):\n",
    "            clean_slices, noisy_slices = clean_slices.to(device), noisy_slices.to(device)\n",
    "\n",
    "            for i in range(clean_slices.size(1)):  # Iterate through each slice\n",
    "                clean_slice = clean_slices[:, i, :, :]\n",
    "                noisy_slice = noisy_slices[:, i, :, :]\n",
    "                outputs = model(noisy_slice)\n",
    "                slice_loss = criterion(outputs, clean_slice)\n",
    "\n",
    "                running_loss += slice_loss.item()\n",
    "                running_psnr += calculate_psnr(clean_slice, outputs)\n",
    "                running_ssim += calculate_ssim(clean_slice, outputs)\n",
    "\n",
    "    avg_loss = running_loss / (len(dataloader) * clean_slices.size(1))\n",
    "    avg_psnr = running_psnr / (len(dataloader) * clean_slices.size(1))\n",
    "    avg_ssim = running_ssim / (len(dataloader) * clean_slices.size(1))\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}, validation loss: {avg_loss:.4f}, PSNR: {avg_psnr:.4f}, SSIM: {avg_ssim:.4f}\")\n",
    "    return avg_loss, avg_psnr, avg_ssim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model, train_loader, val_loader, num_epochs, device, log_dir, checkpoint_dir):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    writer = SummaryWriter(log_dir)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train(model, train_loader, criterion, optimizer, scheduler, device, epoch)\n",
    "        val_loss, val_psnr, val_ssim = validate(model, val_loader, criterion, device, epoch)\n",
    "\n",
    "        # Save a checkpoint at the end of each epoch\n",
    "        \"\"\"\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'loss': val_loss,\n",
    "            'psnr': val_psnr,\n",
    "            'ssim': val_ssim\n",
    "        }, os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch}.pt'))\n",
    "        \"\"\"\n",
    "        # \n",
    "        writer.add_scalar('Training Loss', train_loss, epoch)\n",
    "        writer.add_scalar('Validation Loss', val_loss, epoch)\n",
    "        #writer.add_scalars(\"Losses\", {\"Train\": train_loss, \"Val\": val_loss}, epoch)\n",
    "        writer.add_scalar('Validation PSNR', val_psnr, epoch)\n",
    "        writer.add_scalar('Validation SSIM', val_ssim, epoch)\n",
    "        \n",
    "        \n",
    "        # Save the best model\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            torch.save(model.state_dict(), os.path.join(checkpoint_dir, 'best_model.pt'))\n",
    "            print(f\"Best model saved at epoch {epoch + 1} with val loss: {best_loss:.4f}\")\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "Epoch 1, training Loss: 0.0046\n",
      "Epoch 1, validation loss: 0.0034, PSNR: 19.8146, SSIM: 0.5657\n",
      "Best model saved at epoch 1 with val loss: 0.0034\n",
      "Epoch 2, training Loss: 0.0023\n",
      "Epoch 2, validation loss: 0.0190, PSNR: 13.8441, SSIM: 0.3415\n",
      "Epoch 3, training Loss: 0.0021\n",
      "Epoch 3, validation loss: 0.0072, PSNR: 16.8728, SSIM: 0.3870\n",
      "Epoch 4, training Loss: 0.0043\n",
      "Epoch 4, validation loss: 0.0051, PSNR: 17.8331, SSIM: 0.4136\n",
      "Epoch 5, training Loss: 0.0043\n",
      "Epoch 5, validation loss: 0.0051, PSNR: 17.8450, SSIM: 0.4104\n",
      "Epoch 6, training Loss: 0.0059\n",
      "Epoch 6, validation loss: 0.0048, PSNR: 18.0468, SSIM: 0.4090\n",
      "Epoch 7, training Loss: 0.0061\n",
      "Epoch 7, validation loss: 0.0052, PSNR: 17.8308, SSIM: 0.4035\n",
      "Epoch 8, training Loss: 0.0060\n",
      "Epoch 8, validation loss: 0.0062, PSNR: 17.3000, SSIM: 0.3962\n",
      "Epoch 9, training Loss: 0.0055\n",
      "Epoch 9, validation loss: 0.0044, PSNR: 18.4613, SSIM: 0.4424\n",
      "Epoch 10, training Loss: 0.0040\n",
      "Epoch 10, validation loss: 0.0036, PSNR: 19.4362, SSIM: 0.5356\n",
      "Epoch 11, training Loss: 0.0019\n",
      "Epoch 11, validation loss: 0.0027, PSNR: 20.5127, SSIM: 0.5747\n",
      "Best model saved at epoch 11 with val loss: 0.0027\n",
      "Epoch 12, training Loss: 0.0018\n",
      "Epoch 12, validation loss: 0.0027, PSNR: 20.5679, SSIM: 0.5758\n",
      "Best model saved at epoch 12 with val loss: 0.0027\n",
      "Epoch 13, training Loss: 0.0029\n",
      "Epoch 13, validation loss: 0.0032, PSNR: 19.8894, SSIM: 0.5400\n",
      "Epoch 14, training Loss: 0.0023\n",
      "Epoch 14, validation loss: 0.0031, PSNR: 20.0832, SSIM: 0.5529\n",
      "Epoch 15, training Loss: 0.0017\n",
      "Epoch 15, validation loss: 0.0026, PSNR: 20.6784, SSIM: 0.5843\n",
      "Best model saved at epoch 15 with val loss: 0.0026\n",
      "Epoch 16, training Loss: 0.0023\n",
      "Epoch 16, validation loss: 0.0024, PSNR: 20.9265, SSIM: 0.5944\n",
      "Best model saved at epoch 16 with val loss: 0.0024\n",
      "Epoch 17, training Loss: 0.0025\n",
      "Epoch 17, validation loss: 0.0036, PSNR: 19.5031, SSIM: 0.5476\n",
      "Epoch 18, training Loss: 0.0015\n",
      "Epoch 18, validation loss: 0.0026, PSNR: 20.7060, SSIM: 0.5898\n",
      "Epoch 19, training Loss: 0.0016\n",
      "Epoch 19, validation loss: 0.0036, PSNR: 19.6426, SSIM: 0.5400\n",
      "Epoch 20, training Loss: 0.0024\n",
      "Epoch 20, validation loss: 0.0036, PSNR: 19.4844, SSIM: 0.5549\n",
      "Epoch 21, training Loss: 0.0026\n",
      "Epoch 21, validation loss: 0.0038, PSNR: 19.4789, SSIM: 0.5392\n",
      "Epoch 22, training Loss: 0.0026\n",
      "Epoch 22, validation loss: 0.0026, PSNR: 20.7012, SSIM: 0.5701\n",
      "Epoch 23, training Loss: 0.0022\n",
      "Epoch 23, validation loss: 0.0023, PSNR: 21.0932, SSIM: 0.5811\n",
      "Best model saved at epoch 23 with val loss: 0.0023\n",
      "Epoch 24, training Loss: 0.0022\n",
      "Epoch 24, validation loss: 0.0027, PSNR: 20.7197, SSIM: 0.5616\n",
      "Epoch 25, training Loss: 0.0025\n",
      "Epoch 25, validation loss: 0.0028, PSNR: 20.4767, SSIM: 0.5612\n",
      "Epoch 26, training Loss: 0.0016\n",
      "Epoch 26, validation loss: 0.0031, PSNR: 20.1494, SSIM: 0.5573\n",
      "Epoch 27, training Loss: 0.0022\n",
      "Epoch 27, validation loss: 0.0051, PSNR: 18.5427, SSIM: 0.5145\n",
      "Epoch 28, training Loss: 0.0021\n",
      "Epoch 28, validation loss: 0.0026, PSNR: 20.8716, SSIM: 0.5699\n",
      "Epoch 29, training Loss: 0.0021\n",
      "Epoch 29, validation loss: 0.0027, PSNR: 20.6758, SSIM: 0.5659\n",
      "Epoch 30, training Loss: 0.0014\n",
      "Epoch 30, validation loss: 0.0024, PSNR: 21.1171, SSIM: 0.5862\n",
      "Epoch 31, training Loss: 0.0021\n",
      "Epoch 31, validation loss: 0.0024, PSNR: 21.0615, SSIM: 0.5715\n",
      "Epoch 32, training Loss: 0.0015\n",
      "Epoch 32, validation loss: 0.0023, PSNR: 21.2054, SSIM: 0.5842\n",
      "Best model saved at epoch 32 with val loss: 0.0023\n",
      "Epoch 33, training Loss: 0.0024\n",
      "Epoch 33, validation loss: 0.0024, PSNR: 21.0710, SSIM: 0.5768\n",
      "Epoch 34, training Loss: 0.0021\n",
      "Epoch 34, validation loss: 0.0026, PSNR: 20.8709, SSIM: 0.5657\n",
      "Epoch 35, training Loss: 0.0015\n",
      "Epoch 35, validation loss: 0.0030, PSNR: 20.3456, SSIM: 0.5565\n",
      "Epoch 36, training Loss: 0.0021\n",
      "Epoch 36, validation loss: 0.0027, PSNR: 20.7219, SSIM: 0.5630\n",
      "Epoch 37, training Loss: 0.0015\n",
      "Epoch 37, validation loss: 0.0029, PSNR: 20.5463, SSIM: 0.5595\n",
      "Epoch 38, training Loss: 0.0015\n",
      "Epoch 38, validation loss: 0.0023, PSNR: 21.2446, SSIM: 0.5838\n",
      "Best model saved at epoch 38 with val loss: 0.0023\n",
      "Epoch 39, training Loss: 0.0024\n",
      "Epoch 39, validation loss: 0.0024, PSNR: 21.0438, SSIM: 0.5740\n",
      "Epoch 40, training Loss: 0.0021\n",
      "Epoch 40, validation loss: 0.0027, PSNR: 20.7276, SSIM: 0.5614\n",
      "Epoch 41, training Loss: 0.0021\n",
      "Epoch 41, validation loss: 0.0027, PSNR: 20.6983, SSIM: 0.5611\n",
      "Epoch 42, training Loss: 0.0021\n",
      "Epoch 42, validation loss: 0.0028, PSNR: 20.6775, SSIM: 0.5608\n",
      "Epoch 43, training Loss: 0.0023\n",
      "Epoch 43, validation loss: 0.0024, PSNR: 21.0577, SSIM: 0.5760\n",
      "Epoch 44, training Loss: 0.0021\n",
      "Epoch 44, validation loss: 0.0026, PSNR: 20.8746, SSIM: 0.5652\n",
      "Epoch 45, training Loss: 0.0021\n",
      "Epoch 45, validation loss: 0.0026, PSNR: 20.8723, SSIM: 0.5651\n",
      "Epoch 46, training Loss: 0.0015\n",
      "Epoch 46, validation loss: 0.0023, PSNR: 21.2032, SSIM: 0.5835\n",
      "Epoch 47, training Loss: 0.0015\n",
      "Epoch 47, validation loss: 0.0030, PSNR: 20.4080, SSIM: 0.5554\n",
      "Epoch 48, training Loss: 0.0023\n",
      "Epoch 48, validation loss: 0.0024, PSNR: 21.0617, SSIM: 0.5759\n",
      "Epoch 49, training Loss: 0.0015\n",
      "Epoch 49, validation loss: 0.0023, PSNR: 21.2065, SSIM: 0.5835\n",
      "Epoch 50, training Loss: 0.0023\n",
      "Epoch 50, validation loss: 0.0024, PSNR: 21.0607, SSIM: 0.5758\n",
      "Epoch 51, training Loss: 0.0015\n",
      "Epoch 51, validation loss: 0.0023, PSNR: 21.2062, SSIM: 0.5835\n",
      "Epoch 52, training Loss: 0.0021\n",
      "Epoch 52, validation loss: 0.0026, PSNR: 20.8595, SSIM: 0.5648\n",
      "Epoch 53, training Loss: 0.0015\n",
      "Epoch 53, validation loss: 0.0030, PSNR: 20.3883, SSIM: 0.5550\n",
      "Epoch 54, training Loss: 0.0015\n",
      "Epoch 54, validation loss: 0.0030, PSNR: 20.3880, SSIM: 0.5550\n",
      "Epoch 55, training Loss: 0.0022\n",
      "Epoch 55, validation loss: 0.0037, PSNR: 19.6082, SSIM: 0.5304\n",
      "Epoch 56, training Loss: 0.0023\n",
      "Epoch 56, validation loss: 0.0024, PSNR: 21.0608, SSIM: 0.5758\n",
      "Epoch 57, training Loss: 0.0015\n",
      "Epoch 57, validation loss: 0.0023, PSNR: 21.2070, SSIM: 0.5835\n",
      "Epoch 58, training Loss: 0.0015\n",
      "Epoch 58, validation loss: 0.0030, PSNR: 20.3862, SSIM: 0.5550\n",
      "Epoch 59, training Loss: 0.0023\n",
      "Epoch 59, validation loss: 0.0024, PSNR: 21.0609, SSIM: 0.5758\n",
      "Epoch 60, training Loss: 0.0022\n",
      "Epoch 60, validation loss: 0.0037, PSNR: 19.6057, SSIM: 0.5304\n",
      "Epoch 61, training Loss: 0.0022\n",
      "Epoch 61, validation loss: 0.0037, PSNR: 19.6052, SSIM: 0.5304\n",
      "Epoch 62, training Loss: 0.0021\n",
      "Epoch 62, validation loss: 0.0026, PSNR: 20.8585, SSIM: 0.5648\n",
      "Epoch 63, training Loss: 0.0022\n",
      "Epoch 63, validation loss: 0.0037, PSNR: 19.6050, SSIM: 0.5303\n",
      "Epoch 64, training Loss: 0.0021\n",
      "Epoch 64, validation loss: 0.0026, PSNR: 20.8584, SSIM: 0.5648\n",
      "Epoch 65, training Loss: 0.0015\n",
      "Epoch 65, validation loss: 0.0030, PSNR: 20.3847, SSIM: 0.5549\n",
      "Epoch 66, training Loss: 0.0015\n",
      "Epoch 66, validation loss: 0.0023, PSNR: 21.2078, SSIM: 0.5835\n",
      "Epoch 67, training Loss: 0.0015\n",
      "Epoch 67, validation loss: 0.0030, PSNR: 20.3845, SSIM: 0.5549\n",
      "Epoch 68, training Loss: 0.0015\n",
      "Epoch 68, validation loss: 0.0030, PSNR: 20.3844, SSIM: 0.5549\n",
      "Epoch 69, training Loss: 0.0021\n",
      "Epoch 69, validation loss: 0.0028, PSNR: 20.6096, SSIM: 0.5599\n",
      "Epoch 70, training Loss: 0.0015\n",
      "Epoch 70, validation loss: 0.0023, PSNR: 21.2079, SSIM: 0.5835\n",
      "Epoch 71, training Loss: 0.0015\n",
      "Epoch 71, validation loss: 0.0023, PSNR: 21.2079, SSIM: 0.5835\n",
      "Epoch 72, training Loss: 0.0023\n",
      "Epoch 72, validation loss: 0.0024, PSNR: 21.0610, SSIM: 0.5758\n",
      "Epoch 73, training Loss: 0.0022\n",
      "Epoch 73, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 74, training Loss: 0.0023\n",
      "Epoch 74, validation loss: 0.0024, PSNR: 21.0610, SSIM: 0.5758\n",
      "Epoch 75, training Loss: 0.0021\n",
      "Epoch 75, validation loss: 0.0028, PSNR: 20.6095, SSIM: 0.5599\n",
      "Epoch 76, training Loss: 0.0021\n",
      "Epoch 76, validation loss: 0.0028, PSNR: 20.6095, SSIM: 0.5599\n",
      "Epoch 77, training Loss: 0.0023\n",
      "Epoch 77, validation loss: 0.0024, PSNR: 21.0610, SSIM: 0.5758\n",
      "Epoch 78, training Loss: 0.0022\n",
      "Epoch 78, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 79, training Loss: 0.0021\n",
      "Epoch 79, validation loss: 0.0026, PSNR: 20.8580, SSIM: 0.5648\n",
      "Epoch 80, training Loss: 0.0015\n",
      "Epoch 80, validation loss: 0.0023, PSNR: 21.2079, SSIM: 0.5835\n",
      "Epoch 81, training Loss: 0.0022\n",
      "Epoch 81, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 82, training Loss: 0.0021\n",
      "Epoch 82, validation loss: 0.0026, PSNR: 20.8580, SSIM: 0.5648\n",
      "Epoch 83, training Loss: 0.0022\n",
      "Epoch 83, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 84, training Loss: 0.0021\n",
      "Epoch 84, validation loss: 0.0028, PSNR: 20.6095, SSIM: 0.5599\n",
      "Epoch 85, training Loss: 0.0021\n",
      "Epoch 85, validation loss: 0.0028, PSNR: 20.6095, SSIM: 0.5599\n",
      "Epoch 86, training Loss: 0.0015\n",
      "Epoch 86, validation loss: 0.0030, PSNR: 20.3841, SSIM: 0.5549\n",
      "Epoch 87, training Loss: 0.0021\n",
      "Epoch 87, validation loss: 0.0028, PSNR: 20.6095, SSIM: 0.5599\n",
      "Epoch 88, training Loss: 0.0015\n",
      "Epoch 88, validation loss: 0.0023, PSNR: 21.2079, SSIM: 0.5835\n",
      "Epoch 89, training Loss: 0.0022\n",
      "Epoch 89, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 90, training Loss: 0.0023\n",
      "Epoch 90, validation loss: 0.0024, PSNR: 21.0610, SSIM: 0.5758\n",
      "Epoch 91, training Loss: 0.0021\n",
      "Epoch 91, validation loss: 0.0028, PSNR: 20.6095, SSIM: 0.5599\n",
      "Epoch 92, training Loss: 0.0022\n",
      "Epoch 92, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 93, training Loss: 0.0022\n",
      "Epoch 93, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 94, training Loss: 0.0021\n",
      "Epoch 94, validation loss: 0.0026, PSNR: 20.8580, SSIM: 0.5648\n",
      "Epoch 95, training Loss: 0.0022\n",
      "Epoch 95, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 96, training Loss: 0.0015\n",
      "Epoch 96, validation loss: 0.0030, PSNR: 20.3841, SSIM: 0.5549\n",
      "Epoch 97, training Loss: 0.0021\n",
      "Epoch 97, validation loss: 0.0026, PSNR: 20.8580, SSIM: 0.5648\n",
      "Epoch 98, training Loss: 0.0022\n",
      "Epoch 98, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 99, training Loss: 0.0021\n",
      "Epoch 99, validation loss: 0.0026, PSNR: 20.8580, SSIM: 0.5648\n",
      "Epoch 100, training Loss: 0.0023\n",
      "Epoch 100, validation loss: 0.0024, PSNR: 21.0610, SSIM: 0.5758\n",
      "Epoch 101, training Loss: 0.0015\n",
      "Epoch 101, validation loss: 0.0023, PSNR: 21.2079, SSIM: 0.5835\n",
      "Epoch 102, training Loss: 0.0015\n",
      "Epoch 102, validation loss: 0.0023, PSNR: 21.2079, SSIM: 0.5835\n",
      "Epoch 103, training Loss: 0.0015\n",
      "Epoch 103, validation loss: 0.0023, PSNR: 21.2079, SSIM: 0.5835\n",
      "Epoch 104, training Loss: 0.0021\n",
      "Epoch 104, validation loss: 0.0026, PSNR: 20.8580, SSIM: 0.5648\n",
      "Epoch 105, training Loss: 0.0023\n",
      "Epoch 105, validation loss: 0.0024, PSNR: 21.0610, SSIM: 0.5758\n",
      "Epoch 106, training Loss: 0.0021\n",
      "Epoch 106, validation loss: 0.0028, PSNR: 20.6095, SSIM: 0.5599\n",
      "Epoch 107, training Loss: 0.0015\n",
      "Epoch 107, validation loss: 0.0023, PSNR: 21.2079, SSIM: 0.5835\n",
      "Epoch 108, training Loss: 0.0021\n",
      "Epoch 108, validation loss: 0.0028, PSNR: 20.6095, SSIM: 0.5599\n",
      "Epoch 109, training Loss: 0.0022\n",
      "Epoch 109, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 110, training Loss: 0.0015\n",
      "Epoch 110, validation loss: 0.0023, PSNR: 21.2079, SSIM: 0.5835\n",
      "Epoch 111, training Loss: 0.0022\n",
      "Epoch 111, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 112, training Loss: 0.0023\n",
      "Epoch 112, validation loss: 0.0024, PSNR: 21.0610, SSIM: 0.5758\n",
      "Epoch 113, training Loss: 0.0015\n",
      "Epoch 113, validation loss: 0.0023, PSNR: 21.2079, SSIM: 0.5835\n",
      "Epoch 114, training Loss: 0.0015\n",
      "Epoch 114, validation loss: 0.0030, PSNR: 20.3841, SSIM: 0.5549\n",
      "Epoch 115, training Loss: 0.0021\n",
      "Epoch 115, validation loss: 0.0026, PSNR: 20.8580, SSIM: 0.5648\n",
      "Epoch 116, training Loss: 0.0021\n",
      "Epoch 116, validation loss: 0.0028, PSNR: 20.6095, SSIM: 0.5599\n",
      "Epoch 117, training Loss: 0.0022\n",
      "Epoch 117, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 118, training Loss: 0.0015\n",
      "Epoch 118, validation loss: 0.0030, PSNR: 20.3841, SSIM: 0.5549\n",
      "Epoch 119, training Loss: 0.0022\n",
      "Epoch 119, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 120, training Loss: 0.0015\n",
      "Epoch 120, validation loss: 0.0030, PSNR: 20.3841, SSIM: 0.5549\n",
      "Epoch 121, training Loss: 0.0021\n",
      "Epoch 121, validation loss: 0.0028, PSNR: 20.6095, SSIM: 0.5599\n",
      "Epoch 122, training Loss: 0.0015\n",
      "Epoch 122, validation loss: 0.0023, PSNR: 21.2079, SSIM: 0.5835\n",
      "Epoch 123, training Loss: 0.0022\n",
      "Epoch 123, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 124, training Loss: 0.0015\n",
      "Epoch 124, validation loss: 0.0030, PSNR: 20.3841, SSIM: 0.5549\n",
      "Epoch 125, training Loss: 0.0023\n",
      "Epoch 125, validation loss: 0.0024, PSNR: 21.0610, SSIM: 0.5758\n",
      "Epoch 126, training Loss: 0.0015\n",
      "Epoch 126, validation loss: 0.0023, PSNR: 21.2079, SSIM: 0.5835\n",
      "Epoch 127, training Loss: 0.0021\n",
      "Epoch 127, validation loss: 0.0028, PSNR: 20.6095, SSIM: 0.5599\n",
      "Epoch 128, training Loss: 0.0023\n",
      "Epoch 128, validation loss: 0.0024, PSNR: 21.0610, SSIM: 0.5758\n",
      "Epoch 129, training Loss: 0.0022\n",
      "Epoch 129, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 130, training Loss: 0.0015\n",
      "Epoch 130, validation loss: 0.0030, PSNR: 20.3841, SSIM: 0.5549\n",
      "Epoch 131, training Loss: 0.0015\n",
      "Epoch 131, validation loss: 0.0030, PSNR: 20.3841, SSIM: 0.5549\n",
      "Epoch 132, training Loss: 0.0022\n",
      "Epoch 132, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 133, training Loss: 0.0015\n",
      "Epoch 133, validation loss: 0.0023, PSNR: 21.2079, SSIM: 0.5835\n",
      "Epoch 134, training Loss: 0.0015\n",
      "Epoch 134, validation loss: 0.0023, PSNR: 21.2079, SSIM: 0.5835\n",
      "Epoch 135, training Loss: 0.0015\n",
      "Epoch 135, validation loss: 0.0030, PSNR: 20.3841, SSIM: 0.5549\n",
      "Epoch 136, training Loss: 0.0021\n",
      "Epoch 136, validation loss: 0.0028, PSNR: 20.6095, SSIM: 0.5599\n",
      "Epoch 137, training Loss: 0.0023\n",
      "Epoch 137, validation loss: 0.0024, PSNR: 21.0610, SSIM: 0.5758\n",
      "Epoch 138, training Loss: 0.0021\n",
      "Epoch 138, validation loss: 0.0028, PSNR: 20.6095, SSIM: 0.5599\n",
      "Epoch 139, training Loss: 0.0023\n",
      "Epoch 139, validation loss: 0.0024, PSNR: 21.0610, SSIM: 0.5758\n",
      "Epoch 140, training Loss: 0.0021\n",
      "Epoch 140, validation loss: 0.0026, PSNR: 20.8580, SSIM: 0.5648\n",
      "Epoch 141, training Loss: 0.0022\n",
      "Epoch 141, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 142, training Loss: 0.0023\n",
      "Epoch 142, validation loss: 0.0024, PSNR: 21.0610, SSIM: 0.5758\n",
      "Epoch 143, training Loss: 0.0022\n",
      "Epoch 143, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 144, training Loss: 0.0015\n",
      "Epoch 144, validation loss: 0.0030, PSNR: 20.3841, SSIM: 0.5549\n",
      "Epoch 145, training Loss: 0.0021\n",
      "Epoch 145, validation loss: 0.0026, PSNR: 20.8580, SSIM: 0.5648\n",
      "Epoch 146, training Loss: 0.0023\n",
      "Epoch 146, validation loss: 0.0024, PSNR: 21.0610, SSIM: 0.5758\n",
      "Epoch 147, training Loss: 0.0015\n",
      "Epoch 147, validation loss: 0.0023, PSNR: 21.2079, SSIM: 0.5835\n",
      "Epoch 148, training Loss: 0.0023\n",
      "Epoch 148, validation loss: 0.0024, PSNR: 21.0610, SSIM: 0.5758\n",
      "Epoch 149, training Loss: 0.0015\n",
      "Epoch 149, validation loss: 0.0030, PSNR: 20.3841, SSIM: 0.5549\n",
      "Epoch 150, training Loss: 0.0021\n",
      "Epoch 150, validation loss: 0.0026, PSNR: 20.8580, SSIM: 0.5648\n",
      "Epoch 151, training Loss: 0.0023\n",
      "Epoch 151, validation loss: 0.0024, PSNR: 21.0610, SSIM: 0.5758\n",
      "Epoch 152, training Loss: 0.0015\n",
      "Epoch 152, validation loss: 0.0030, PSNR: 20.3841, SSIM: 0.5549\n",
      "Epoch 153, training Loss: 0.0022\n",
      "Epoch 153, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 154, training Loss: 0.0023\n",
      "Epoch 154, validation loss: 0.0024, PSNR: 21.0610, SSIM: 0.5758\n",
      "Epoch 155, training Loss: 0.0015\n",
      "Epoch 155, validation loss: 0.0023, PSNR: 21.2079, SSIM: 0.5835\n",
      "Epoch 156, training Loss: 0.0021\n",
      "Epoch 156, validation loss: 0.0026, PSNR: 20.8580, SSIM: 0.5648\n",
      "Epoch 157, training Loss: 0.0022\n",
      "Epoch 157, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 158, training Loss: 0.0022\n",
      "Epoch 158, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 159, training Loss: 0.0015\n",
      "Epoch 159, validation loss: 0.0030, PSNR: 20.3841, SSIM: 0.5549\n",
      "Epoch 160, training Loss: 0.0021\n",
      "Epoch 160, validation loss: 0.0028, PSNR: 20.6095, SSIM: 0.5599\n",
      "Epoch 161, training Loss: 0.0022\n",
      "Epoch 161, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 162, training Loss: 0.0022\n",
      "Epoch 162, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 163, training Loss: 0.0015\n",
      "Epoch 163, validation loss: 0.0030, PSNR: 20.3841, SSIM: 0.5549\n",
      "Epoch 164, training Loss: 0.0015\n",
      "Epoch 164, validation loss: 0.0023, PSNR: 21.2079, SSIM: 0.5835\n",
      "Epoch 165, training Loss: 0.0015\n",
      "Epoch 165, validation loss: 0.0030, PSNR: 20.3841, SSIM: 0.5549\n",
      "Epoch 166, training Loss: 0.0022\n",
      "Epoch 166, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 167, training Loss: 0.0023\n",
      "Epoch 167, validation loss: 0.0024, PSNR: 21.0610, SSIM: 0.5758\n",
      "Epoch 168, training Loss: 0.0022\n",
      "Epoch 168, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 169, training Loss: 0.0021\n",
      "Epoch 169, validation loss: 0.0026, PSNR: 20.8580, SSIM: 0.5648\n",
      "Epoch 170, training Loss: 0.0023\n",
      "Epoch 170, validation loss: 0.0024, PSNR: 21.0610, SSIM: 0.5758\n",
      "Epoch 171, training Loss: 0.0015\n",
      "Epoch 171, validation loss: 0.0030, PSNR: 20.3841, SSIM: 0.5549\n",
      "Epoch 172, training Loss: 0.0023\n",
      "Epoch 172, validation loss: 0.0024, PSNR: 21.0610, SSIM: 0.5758\n",
      "Epoch 173, training Loss: 0.0023\n",
      "Epoch 173, validation loss: 0.0024, PSNR: 21.0610, SSIM: 0.5758\n",
      "Epoch 174, training Loss: 0.0023\n",
      "Epoch 174, validation loss: 0.0024, PSNR: 21.0610, SSIM: 0.5758\n",
      "Epoch 175, training Loss: 0.0015\n",
      "Epoch 175, validation loss: 0.0030, PSNR: 20.3841, SSIM: 0.5549\n",
      "Epoch 176, training Loss: 0.0015\n",
      "Epoch 176, validation loss: 0.0030, PSNR: 20.3841, SSIM: 0.5549\n",
      "Epoch 177, training Loss: 0.0022\n",
      "Epoch 177, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 178, training Loss: 0.0021\n",
      "Epoch 178, validation loss: 0.0026, PSNR: 20.8580, SSIM: 0.5648\n",
      "Epoch 179, training Loss: 0.0023\n",
      "Epoch 179, validation loss: 0.0024, PSNR: 21.0610, SSIM: 0.5758\n",
      "Epoch 180, training Loss: 0.0022\n",
      "Epoch 180, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 181, training Loss: 0.0023\n",
      "Epoch 181, validation loss: 0.0024, PSNR: 21.0610, SSIM: 0.5758\n",
      "Epoch 182, training Loss: 0.0015\n",
      "Epoch 182, validation loss: 0.0030, PSNR: 20.3841, SSIM: 0.5549\n",
      "Epoch 183, training Loss: 0.0022\n",
      "Epoch 183, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 184, training Loss: 0.0021\n",
      "Epoch 184, validation loss: 0.0026, PSNR: 20.8580, SSIM: 0.5648\n",
      "Epoch 185, training Loss: 0.0015\n",
      "Epoch 185, validation loss: 0.0030, PSNR: 20.3841, SSIM: 0.5549\n",
      "Epoch 186, training Loss: 0.0023\n",
      "Epoch 186, validation loss: 0.0024, PSNR: 21.0610, SSIM: 0.5758\n",
      "Epoch 187, training Loss: 0.0023\n",
      "Epoch 187, validation loss: 0.0024, PSNR: 21.0610, SSIM: 0.5758\n",
      "Epoch 188, training Loss: 0.0023\n",
      "Epoch 188, validation loss: 0.0024, PSNR: 21.0610, SSIM: 0.5758\n",
      "Epoch 189, training Loss: 0.0022\n",
      "Epoch 189, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 190, training Loss: 0.0021\n",
      "Epoch 190, validation loss: 0.0028, PSNR: 20.6095, SSIM: 0.5599\n",
      "Epoch 191, training Loss: 0.0015\n",
      "Epoch 191, validation loss: 0.0030, PSNR: 20.3841, SSIM: 0.5549\n",
      "Epoch 192, training Loss: 0.0015\n",
      "Epoch 192, validation loss: 0.0030, PSNR: 20.3841, SSIM: 0.5549\n",
      "Epoch 193, training Loss: 0.0022\n",
      "Epoch 193, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 194, training Loss: 0.0022\n",
      "Epoch 194, validation loss: 0.0037, PSNR: 19.6042, SSIM: 0.5303\n",
      "Epoch 195, training Loss: 0.0015\n",
      "Epoch 195, validation loss: 0.0023, PSNR: 21.2079, SSIM: 0.5835\n",
      "Epoch 196, training Loss: 0.0015\n",
      "Epoch 196, validation loss: 0.0030, PSNR: 20.3841, SSIM: 0.5549\n",
      "Epoch 197, training Loss: 0.0015\n",
      "Epoch 197, validation loss: 0.0023, PSNR: 21.2079, SSIM: 0.5835\n",
      "Epoch 198, training Loss: 0.0015\n",
      "Epoch 198, validation loss: 0.0030, PSNR: 20.3841, SSIM: 0.5549\n",
      "Epoch 199, training Loss: 0.0015\n",
      "Epoch 199, validation loss: 0.0023, PSNR: 21.2079, SSIM: 0.5835\n",
      "Epoch 200, training Loss: 0.0021\n",
      "Epoch 200, validation loss: 0.0026, PSNR: 20.8580, SSIM: 0.5648\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")\n",
    "\n",
    "num_epochs = 200\n",
    "\n",
    "task_name = f\"DnCNN_lam5_MSE_epoch{num_epochs}\"\n",
    "\n",
    "log_dir = f\"/root/tf-logs/runs/{task_name}\"\n",
    "checkpoint_dir = f\"checkpoints/{task_name}\"\n",
    "\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "model = DnCNN().to(device)\n",
    "\n",
    "# start trainging\n",
    "start_time = time.time()\n",
    "train_and_validate(model, train_loader, val_loader, num_epochs, device, log_dir, checkpoint_dir)\n",
    "end_time = time.time()\n",
    "total_second = int(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"code\":\"Success\",\"data\":null,\"msg\":\"\"}\n"
     ]
    }
   ],
   "source": [
    "# send result to wechat \n",
    "\n",
    "import requests\n",
    "headers = {\"Authorization\": \"eyJhbGciOiJFUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1aWQiOjM5MjI4LCJ1dWlkIjoiNTAyZTcyM2ItZjY2Mi00YTk4LWJkZmEtMzc1ZjdlOWM5NmFlIiwiaXNfYWRtaW4iOmZhbHNlLCJpc19zdXBlcl9hZG1pbiI6ZmFsc2UsInN1Yl9uYW1lIjoiIiwidGVuYW50IjoiYXV0b2RsIiwidXBrIjoiIn0.0IybMXdA-3z6KDYJDDGCj-_qqw6o4kya5usOFcLUtFL-ewBe35RnN8COQn4lO3umL-rWJ3er2PsIWZBjIl5XJw\"}\n",
    "resp = requests.post(\"https://www.autodl.com/api/v1/wechat/message/send\",\n",
    "                     json={\n",
    "                         \"title\": \"训练结束\",\n",
    "                         \"name\": task_name,\n",
    "                         \"content\": f\"training time: {total_second // 3600}h {(total_second % 3600) // 60}m\"\n",
    "                     }, headers = headers)\n",
    "\n",
    "print(resp.content.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluations model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_psnr = 0.0\n",
    "    running_ssim = 0.0\n",
    "\n",
    "    denoised_slices_list = []\n",
    "    clean_slices_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (clean_slices, noisy_slices) in enumerate(dataloader):\n",
    "            clean_slices, noisy_slices = clean_slices.to(device), noisy_slices.to(device)\n",
    "\n",
    "            denoised_slices = []\n",
    "\n",
    "            for i in range(clean_slices.size(1)):  # Iterate through each slice\n",
    "                clean_slice = clean_slices[:, i, :, :]\n",
    "                noisy_slice = noisy_slices[:, i, :, :]\n",
    "                outputs = model(noisy_slice)\n",
    "\n",
    "                denoised_slices.append(outputs)\n",
    "                running_psnr += calculate_psnr(clean_slice, outputs)\n",
    "                running_ssim += calculate_ssim(clean_slice, outputs)\n",
    "\n",
    "            denoised_slices = torch.stack(denoised_slices, dim=1)\n",
    "            denoised_slices_list.append(denoised_slices.cpu())\n",
    "            clean_slices_list.append(clean_slices.cpu())\n",
    "\n",
    "    avg_psnr = running_psnr / (len(dataloader) * clean_slices.size(1))\n",
    "    avg_ssim = running_ssim / (len(dataloader) * clean_slices.size(1))\n",
    "\n",
    "    return denoised_slices_list, clean_slices_list, avg_psnr, avg_ssim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "Average PSNR: 24.8215\n",
      "Average SSIM: 0.6608\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"device: {device}\")\n",
    "\n",
    "model = DnCNN().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "# Load the trained model\n",
    "checkpoint_path = \"checkpoints/DnCNN_lam5_MSE_epoch200/best_model.pt\"\n",
    "model.load_state_dict(torch.load(checkpoint_path))\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "denoised_slices_list, clean_slices_list, avg_psnr, avg_ssim = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"Average PSNR: {avg_psnr:.4f}\")\n",
    "print(f\"Average SSIM: {avg_ssim:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "\n",
    "denoised_slices = denoised_slices_list[idx].squeeze(0)\n",
    "clean_slices = clean_slices_list[idx].squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36dc913e9c634180a8eb0082b774957a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='slice_idx', max=210), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c8b18d5d2944edb4077722a6c0531e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='slice_idx', max=210), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize.plot_slices(denoised_slices)\n",
    "visualize.plot_slices(clean_slices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
